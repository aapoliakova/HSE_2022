{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw05_task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qp0H_zUQuu_"
      },
      "source": [
        "# Нейронные сети\n",
        "__Суммарное количество баллов: 10__\n",
        "\n",
        "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
        "\n",
        "__Тема письма: `[HSE][ML][MS][HW05] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
        "\n",
        "Для начала вам предстоит реализовать свой собственный backpropagation и протестировать его на реальных данных, а затем научиться обучать нейронные сети при помощи библиотеки `PyTorch` и использовать это умение для классификации классического набора данных CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ezVRf3QuvA"
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "from sklearn.datasets import make_blobs, make_moons\n",
        "from typing import List, NoReturn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новый раздел"
      ],
      "metadata": {
        "id": "csaO4xGxuGAE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qfDPH_LQuvF"
      },
      "source": [
        "### Задание 1 (3 балла)\n",
        "Нейронные сети состоят из слоев, поэтому для начала понадобится реализовать их. Пока нам понадобятся только три:\n",
        "\n",
        "`Linear` - полносвязный слой, в котором `y = Wx + b`, где `y` - выход, `x` - вход, `W` - матрица весов, а `b` - смещение. \n",
        "\n",
        "`ReLU` - слой, соответствующий функции активации `y = max(0, x)`.\n",
        "\n",
        "`Softmax` - слой, соответствующий функции активации [softmax](https://ru.wikipedia.org/wiki/Softmax)\n",
        "\n",
        "\n",
        "#### Методы\n",
        "`forward(X)` - возвращает предсказанные для `X`. `X` может быть как вектором, так и батчем\n",
        "\n",
        "`backward(d)` - считает градиент при помощи обратного распространения ошибки. Возвращает новое значение `d`\n",
        "\n",
        "`update(alpha)` - обновляет веса (если необходимо) с заданой скоростью обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWFLlHqaYbgC"
      },
      "source": [
        "class Module:\n",
        "    \"\"\"\n",
        "    Абстрактный класс. Его менять не нужно.\n",
        "    \"\"\"\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def backward(self, d):\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "    def update(self, alpha):\n",
        "        pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYS2gE4PYepZ"
      },
      "source": [
        "class Linear(Module):\n",
        "    \"\"\"\n",
        "    Линейный полносвязный слой.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_in: int, n_out: int):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        in_features : int\n",
        "            Размер входа.\n",
        "        out_features : int\n",
        "            Размер выхода.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        W и b инициализируются случайно.\n",
        "        \"\"\"\n",
        "        stdv = 1. / np.sqrt(n_in)\n",
        "        self.W = np.random.uniform(-stdv, stdv, size=(n_out, n_in))\n",
        "        self.b = np.random.uniform(-stdv, stdv, size=n_out)\n",
        "\n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = Wx + b.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "            То есть, либо x вектор с in_features элементов,\n",
        "            либо матрица размерности (batch_size, in_features).\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя.\n",
        "            Либо вектор с out_features элементами,\n",
        "            либо матрица размерности (batch_size, out_features)\n",
        "\n",
        "        \"\"\"\n",
        "        self.a = x\n",
        "        return self.a @ self.W.T + self.b  # aW.T + b\n",
        "\n",
        "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        self.dW = np.sum(self.a[:, None, :] * grad[:, :, None], axis=0)  # Eq4\n",
        "        self.db = np.sum(grad, axis=0)  # Eq3\n",
        "        # print(f\"Gradient shape is {self.dW.shape} and wights shape : {self.W.shape}\")\n",
        "        return grad @ self.W  # Eq2\n",
        "\n",
        "    def update(self, alpha: float = 0.0001) -> NoReturn:\n",
        "        \"\"\"\n",
        "        Обновляет W и b с заданной скоростью обучения.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        alpha : float\n",
        "            Скорость обучения.\n",
        "        \"\"\"\n",
        "        self.W -= alpha * self.dW\n",
        "        self.b -= alpha * self.db\n",
        "        # print(f\"Wights updated is {self.W.shape}\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94hkbnD1QuvG"
      },
      "source": [
        "class ReLU(Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Слой, соответствующий функции активации ReLU.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward(self, z: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = max(0, x).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        z : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя (той же размерности, что и вход).\n",
        "\n",
        "        \"\"\"\n",
        "        self.z = z\n",
        "        return np.maximum(0, z)\n",
        "\n",
        "    def backward(self, d) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        grad = self.z > 0\n",
        "        return d * grad\n",
        "        "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "class SoftMax(Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Слой, соответствующий функции активации Softmax.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward(self, X: np.ndarray):\n",
        "        \"\"\"\n",
        "        Возвращает y = Softmax(x).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя (той же размерности, что и вход).\n",
        "\n",
        "        \"\"\"\n",
        "        self.n_samples, _ = X.shape\n",
        "        scores = np.subtract(X, X.max(axis=1, keepdims=True))\n",
        "        self.activation = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n",
        "        return self.activation\n",
        "\n",
        "    def compute_loss(self, y: np.ndarray):\n",
        "        \"\"\"\n",
        "        Cчитает loss\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.ndarray\n",
        "            Метки классов\n",
        "        Return\n",
        "        ------\n",
        "        float\n",
        "            Значение функции потерь\n",
        "        \"\"\"\n",
        "        self.mask = np.arange(self.n_samples), y\n",
        "        self.correct_log_prob = self.activation[mask]\n",
        "        self.loss = np.sum(-np.log(self.correct_log_prob)) / self.n_samples\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, y: np.ndarray):\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.ndarray\n",
        "            True labels.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        self.mask = np.arange(self.n_samples), y\n",
        "        self.grad = self.activation\n",
        "        self.grad[self.mask] -= 1\n",
        "        self.grad /= self.n_samples\n",
        "        return self.grad / self.n_samples  # dCost /da * da /dz"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ukI6AMmds-QM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb_ip_h8QuvJ"
      },
      "source": [
        "### Задание 2 (2 балла)\n",
        "Теперь сделаем саму нейронную сеть.\n",
        "\n",
        "#### Методы\n",
        "`fit(X, y)` - обучает нейронную сеть заданное число эпох. В каждой эпохе необходимо использовать [cross-entropy loss](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) для обучения, а так же производить обновления не по одному элементу, а используя батчи.\n",
        "\n",
        "`predict_proba(X)` - предсказывает вероятности классов для элементов `X`\n",
        "\n",
        "#### Параметры конструктора\n",
        "`modules` - список, состоящий из ранее реализованных модулей и описывающий слои нейронной сети. В конец необходимо добавить `Softmax`\n",
        "\n",
        "`epochs` - количество эпох обучения\n",
        "\n",
        "`alpha` - скорость обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def generate_batch(X: np.ndarray, y: np.ndarray, batch_size: int):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : np.ndarray\n",
        "        Данные для обучения.\n",
        "    y : np.ndarray\n",
        "        Вектор меток классов для данных.\n",
        "    batch_size : int\n",
        "        Размер батча.\n",
        "            Return\n",
        "    ------\n",
        "    np.ndarray\n",
        "         батч\n",
        "    \"\"\"\n",
        "    n_samples, _ = X.shape\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        batch_idx = indices[start:end]\n",
        "        yield X[batch_idx], y[batch_idx]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VkHq8JZBs-QN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_JFCizKQuvK"
      },
      "source": [
        "class MLPClassifier:\n",
        "    def __init__(self, layers: List[Module], epochs: int = 40, alpha: float = 0.01):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        modules : list[Module]\n",
        "            Cписок, состоящий из ранее реализованных модулей и\n",
        "            описывающий слои нейронной сети.\n",
        "            В конец необходимо добавить Softmax.\n",
        "        epochs : int\n",
        "            Количество эпох обучения\n",
        "        alpha : float\n",
        "            Cкорость обучения.\n",
        "        \"\"\"\n",
        "        self.layers = layers\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray, batch_size: int = 32) -> NoReturn:\n",
        "        \"\"\"\n",
        "        Обучает нейронную сеть заданное число эпох.\n",
        "        В каждой эпохе необходимо использовать cross-entropy loss для обучения,\n",
        "        а так же производить обновления не по одному элементу, а используя батчи.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для обучения.\n",
        "        y : np.ndarray\n",
        "            Вектор меток классов для данных.\n",
        "        batch_size : int\n",
        "            Размер батча.\n",
        "        \"\"\"\n",
        "        self.layers.append(SoftMax())\n",
        "        for epoch in range(40):\n",
        "            for x_batch, y_batch in generate_batch(X, y, batch_size):\n",
        "                for layer in self.layers:\n",
        "                    x_batch = layer.forward(x_batch)\n",
        "\n",
        "                output_error = y_batch\n",
        "                for layer in reversed(self.layers):\n",
        "                    output_error = layer.backward(output_error)\n",
        "\n",
        "                for layer in self.layers:\n",
        "                    layer.update(self.alpha)\n",
        "        return self\n",
        "                \n",
        "\n",
        "    def predict_proba(self, X: np.ndarray):\n",
        "        \"\"\"\n",
        "        Предсказывает вероятности классов для элементов X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для предсказания.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Предсказанные вероятности классов для всех элементов X.\n",
        "            Размерность (X.shape[0], n_classes)\n",
        "\n",
        "        \"\"\"\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X)\n",
        "        return X\n",
        "\n",
        "    def predict(self, X: np.ndarray):\n",
        "        \"\"\"\n",
        "        Предсказывает метки классов для элементов X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для предсказания.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Вектор предсказанных классов\n",
        "\n",
        "        \"\"\"\n",
        "        p = self.predict_proba(X)\n",
        "        return np.argmax(p, axis=1)\n",
        "\n",
        "\n",
        "def generate_batch(X: np.ndarray, y: np.ndarray, batch_size: int):\n",
        "    \"\"\"\n",
        "    Обучает нейронную сеть заданное число эпох.\n",
        "    В каждой эпохе необходимо использовать cross-entropy loss для обучения,\n",
        "    а так же производить обновления не по одному элементу, а используя батчи.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : np.ndarray\n",
        "        Данные для обучения.\n",
        "    y : np.ndarray\n",
        "        Вектор меток классов для данных.\n",
        "    batch_size : int\n",
        "        Размер батча.\n",
        "            Return\n",
        "    ------\n",
        "    np.ndarray\n",
        "         батч\n",
        "    \"\"\"\n",
        "    n_samples, _ = X.shape\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        batch_idx = indices[start:end]\n",
        "        yield X[batch_idx], y[batch_idx]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.MLPClassifier at 0x7feb2aae40d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "p = MLPClassifier([\n",
        "    Linear(4, 64),\n",
        "    ReLU(),\n",
        "    Linear(64, 64),\n",
        "    ReLU(),\n",
        "    Linear(64, 2)\n",
        "])\n",
        "\n",
        "X = np.random.randn(50, 4)\n",
        "y = np.array([(0 if x[0] > x[2]**2 or x[3]**3 > 0.5 else 1) for x in X])\n",
        "p.fit(X, y)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyIHljzps-QP",
        "outputId": "c1df80ff-d6c2-403f-e666-a23df0260504"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C1EIsDqQuvQ"
      },
      "source": [
        "### Задание 3 (2 балла)\n",
        "Протестируем наше решение на синтетических данных. Необходимо подобрать гиперпараметры, при которых качество полученных классификаторов будет достаточным.\n",
        "\n",
        "#### Оценка\n",
        "Accuracy на первом датасете больше 0.85 - +1 балл\n",
        "\n",
        "Accuracy на втором датасете больше 0.85 - +1 балл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5UAgXTcQuvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839e15ce-5835-4d46-b77c-5eb2e6aceaa1"
      },
      "source": [
        "X, y = make_moons(400, noise=0.075)\n",
        "X_test, y_test = make_moons(400, noise=0.075)\n",
        "\n",
        "best_acc = 0\n",
        "for _ in range(25):\n",
        "    p = MLPClassifier([Linear(2, 64), ReLU(), Linear(64, 2)], alpha=0.9)\n",
        "    p.fit(X, y, batch_size=50)\n",
        "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
        "print(\"Accuracy\", best_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMDJM4qFQuvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7033100-e9d1-442c-d1e7-e4a784b6c8f0"
      },
      "source": [
        "X, y = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
        "X_test, y_test = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "for _ in range(25):\n",
        "    p = MLPClassifier([Linear(2, 4), ReLU(), Linear(4, 3)], alpha=0.9)\n",
        "    p.fit(X, y, batch_size=100)\n",
        "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
        "print(\"Accuracy\", best_acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPbVTFnMQuvW"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "Для выполнения следующего задания понадобится PyTorch. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
        "\n",
        "Если у вас нет GPU, то можно использовать [Google Colab](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV0mJLu-QuvX"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUC_QqpAQuva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d249e27-9d6a-4d72-ef39-17302fe54516"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "t = transforms.ToTensor()\n",
        "\n",
        "cifar_train = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=True, transform=t)\n",
        "train_loader = DataLoader(cifar_train, batch_size=1024, shuffle=True, pin_memory=torch.cuda.is_available())\n",
        "cifar_test = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=False, transform=t)\n",
        "test_loader = DataLoader(cifar_test, batch_size=1024, shuffle=False, pin_memory=torch.cuda.is_available())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGmpjcFfQuvd"
      },
      "source": [
        "### Задание 4 (3 балла)\n",
        "А теперь поработам с настоящими нейронными сетями и настоящими данными. Необходимо реализовать сверточную нейронную сеть, которая будет классифицировать изображения из датасета CIFAR10. Имплементируйте класс `Model` и функцию `calculate_loss`. \n",
        "\n",
        "Обратите внимание, что `Model` должна считать в конце `softmax`, т.к. мы решаем задачу классификации. Соответствеено, функция `calculate_loss` считает cross-entropy.\n",
        "\n",
        "Для успешного выполнения задания необходимо, чтобы `accuracy`, `mean precision` и `mean recall` были больше 0.5\n",
        "\n",
        "__Можно пользоваться всем содержимым библиотеки PyTorch.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sRmTKwKQuve"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self._layers = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1), \n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Conv2d(in_channels = 16, out_channels = 32,\n",
        "                      kernel_size = 4, stride=2, padding=1), \n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Dropout(p=0.25),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), #\n",
        "            nn.LeakyReLU(0.3),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(4096, 256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self._layers(x)\n",
        "\n",
        "def calculate_loss(X: torch.Tensor, y: torch.Tensor, model: Model):\n",
        "    \"\"\"\n",
        "    Cчитает cross-entropy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : torch.Tensor\n",
        "        Данные для обучения.\n",
        "    y : torch.Tensor\n",
        "        Метки классов.\n",
        "    model : Model\n",
        "        Модель, которую будем обучать.\n",
        "\n",
        "    \"\"\"\n",
        "    logits = model(X)\n",
        "    return nn.functional.cross_entropy(logits, y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5G8iMCeQuvh"
      },
      "source": [
        "def train(model, epochs=30):\n",
        "    optimizer = torch.optim.AdamW(model.parameters())\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    for i in range(epochs):\n",
        "        #Train\n",
        "        loss_mean = 0\n",
        "        elements = 0\n",
        "        for X, y in iter(train_loader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            loss = calculate_loss(X, y, model)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_mean += loss.item() * len(X)\n",
        "            elements += len(X)\n",
        "        train_losses.append(loss_mean / elements)\n",
        "        #Test\n",
        "        loss_mean = 0\n",
        "        elements = 0\n",
        "        for X, y in iter(test_loader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            loss = calculate_loss(X, y, model)\n",
        "            loss_mean += loss.item() * len(X)\n",
        "            elements += len(X)\n",
        "        test_losses.append(loss_mean / elements)\n",
        "        print(\"Epoch\", i, \"| Train loss\", train_losses[-1], \"| Test loss\", test_losses[-1])\n",
        "    return train_losses, test_losses"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmD9eWJOQuvl",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd81116-e93f-4b19-dd97-4fd1dee56ff4"
      },
      "source": [
        "model = Model().to(device)\n",
        "train_l, test_l = train(model)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train loss 1.9715412448501586 | Test loss 1.7473465250015259\n",
            "Epoch 1 | Train loss 1.6460583024597168 | Test loss 1.5557739782333373\n",
            "Epoch 2 | Train loss 1.5075569159317017 | Test loss 1.4589485809326173\n",
            "Epoch 3 | Train loss 1.4284841779327393 | Test loss 1.4078540908813477\n",
            "Epoch 4 | Train loss 1.3563048844528198 | Test loss 1.337515311050415\n",
            "Epoch 5 | Train loss 1.2964259609222413 | Test loss 1.3040979232788086\n",
            "Epoch 6 | Train loss 1.2541438743591309 | Test loss 1.2679218170166016\n",
            "Epoch 7 | Train loss 1.2164266105270385 | Test loss 1.242326043319702\n",
            "Epoch 8 | Train loss 1.1688746140670776 | Test loss 1.2222015491485596\n",
            "Epoch 9 | Train loss 1.1344879261398315 | Test loss 1.1995129856109619\n",
            "Epoch 10 | Train loss 1.106653155555725 | Test loss 1.1815533853530884\n",
            "Epoch 11 | Train loss 1.075991270942688 | Test loss 1.162681351852417\n",
            "Epoch 12 | Train loss 1.044145131149292 | Test loss 1.1499019369125367\n",
            "Epoch 13 | Train loss 1.0203792533111573 | Test loss 1.143628347015381\n",
            "Epoch 14 | Train loss 0.9965501269721985 | Test loss 1.1319919761657715\n",
            "Epoch 15 | Train loss 0.9761295096206665 | Test loss 1.1512735246658325\n",
            "Epoch 16 | Train loss 0.968449062461853 | Test loss 1.123380809020996\n",
            "Epoch 17 | Train loss 0.9351627515792846 | Test loss 1.1244000881195069\n",
            "Epoch 18 | Train loss 0.9126126643180847 | Test loss 1.0968858032226563\n",
            "Epoch 19 | Train loss 0.8991427108192444 | Test loss 1.102813013458252\n",
            "Epoch 20 | Train loss 0.871723014831543 | Test loss 1.0973933364868165\n",
            "Epoch 21 | Train loss 0.8492402676582337 | Test loss 1.122030742073059\n",
            "Epoch 22 | Train loss 0.8323444728279114 | Test loss 1.1048583307266235\n",
            "Epoch 23 | Train loss 0.8227334166145325 | Test loss 1.104113444328308\n",
            "Epoch 24 | Train loss 0.8029631641769409 | Test loss 1.10795383644104\n",
            "Epoch 25 | Train loss 0.7855662907791138 | Test loss 1.0965541227340698\n",
            "Epoch 26 | Train loss 0.7732595666122436 | Test loss 1.0977553161621094\n",
            "Epoch 27 | Train loss 0.7533560287666321 | Test loss 1.1025470319747925\n",
            "Epoch 28 | Train loss 0.7401357778358459 | Test loss 1.0967841873168944\n",
            "Epoch 29 | Train loss 0.7276097905158997 | Test loss 1.1156503744125366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJNAuHjNQuvn"
      },
      "source": [
        "Построим график функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6OEGqriQuvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "e03a80d5-08fb-47df-f966-d65b9dae1ff9"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(train_l)), train_l, label=\"train\")\n",
        "plt.plot(range(len(test_l)), test_l, label=\"test\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miUxg0bDQuvs"
      },
      "source": [
        "И, наконец, посчитаем метрики"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXSOJFI8Quvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce699af-c2d3-480a-a450-f84e5ffe9b04"
      },
      "source": [
        "true_positive = np.zeros(10)\n",
        "true_negative = np.zeros(10)\n",
        "false_positive = np.zeros(10)\n",
        "false_negative = np.zeros(10)\n",
        "accuracy = 0\n",
        "ctn = 0\n",
        "for X, y in iter(test_loader):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X).max(dim=1)[1]\n",
        "    for i in range(10):\n",
        "        for pred, real in zip(y_pred, y):\n",
        "            if real == i:\n",
        "                if pred == real:\n",
        "                    true_positive[i] += 1\n",
        "                else:\n",
        "                    false_negative[i] += 1\n",
        "            else:\n",
        "                if pred == i:\n",
        "                    false_positive[i] += 1\n",
        "                else:\n",
        "                    true_negative[i] += 1\n",
        "            \n",
        "    accuracy += torch.sum(y_pred == y).item()\n",
        "    ctn += len(y)\n",
        "print(\"Overall accuracy\", accuracy / ctn)\n",
        "print(\"Precision\", true_positive / (true_positive + false_positive))\n",
        "print(\"Recall\", true_positive / (true_positive + false_negative))\n",
        "print(\"Mean Precision\", np.mean(true_positive / (true_positive + false_positive)))\n",
        "print(\"Mean Recall\", np.mean(true_positive / (true_positive + false_negative)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy 0.6298\n",
            "Precision [0.6754386  0.75751295 0.49731183 0.46842105 0.56075697 0.52983539\n",
            " 0.65070922 0.71231423 0.77491961 0.69294606]\n",
            "Recall [0.693 0.731 0.555 0.445 0.563 0.515 0.734 0.671 0.723 0.668]\n",
            "Mean Precision 0.6320165910656159\n",
            "Mean Recall 0.6298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKA-j4rIQuvv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}