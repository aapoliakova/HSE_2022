{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "sheet_delimiter": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "execution_count": 1,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def to_scalar(x, i=None):\n",
    "    \"\"\"Returns i-th element from an array x if x is array, else returns x\n",
    "Args:\n",
    "    x - input array\n",
    "    i - index to return\n",
    "Returns:\n",
    "    x[i] if x is an array and x else\n",
    "\"\"\"\n",
    "    if isinstance(x, (np.ndarray, list)):\n",
    "        return x[i]\n",
    "    return x"
   ],
   "execution_count": 2,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def gradient_checker(J, grad_J, theta, eps=1e-4, rtol=1e-5):\n",
    "    \"\"\"Gradient checker for scalar and vector functions\n",
    "    Args:\n",
    "        J - function of theta\n",
    "        grad_J - gradient of function J\n",
    "        theta - the point for which to compute the numerical gradient\n",
    "        eps - step value in numerical gradient\n",
    "        rtol - relative tolerance threshold value\n",
    "    Returns:\n",
    "        error message if the relative tolerance is greater for some axis\n",
    "        or \"Gradient check passed\" else\n",
    "    \"\"\"\n",
    "    it = np.nditer(theta, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] += eps\n",
    "        J1 = J(theta_)\n",
    "\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] -= eps\n",
    "        J2 = J(theta_)\n",
    "\n",
    "        J1 = to_scalar(J1, ix)\n",
    "        J2 = to_scalar(J2, ix)\n",
    "\n",
    "        num_grad = (J1 - J2)/(2*eps)\n",
    "\n",
    "        rel_tol = np.abs(num_grad - grad_J(theta))[ix]/(1. + np.minimum(np.abs(num_grad), np.abs(grad_J(theta)[ix])))\n",
    "\n",
    "        if np.all(rel_tol > rtol):\n",
    "            print(f'Incorrect gradient for the axis {str(ix)}')\n",
    "            return\n",
    "        it.iternext()\n",
    "    print(f'Gradient check passed')"
   ],
   "execution_count": 3,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def J_theta_global(model, loss_function, theta, idx, x, y):\n",
    "    previous = model.parameters()[idx].copy()\n",
    "    np.copyto(dst=model.parameters()[idx], src=theta)\n",
    "    outputs = model(x)\n",
    "    loss = loss_function(outputs, y)\n",
    "    np.copyto(dst=model.parameters()[idx], src=previous)\n",
    "    return loss"
   ],
   "execution_count": 4,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def dJ_theta_global(model, loss_function, theta, idx, x):\n",
    "    grad = model.backward(loss_function)[idx] / x.shape[0]\n",
    "    return grad.reshape(theta.shape)"
   ],
   "execution_count": 5,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def sigmoid(x,slope=1.0):\n",
    "    return 1.0/(1.0+np.exp(-slope*x))"
   ],
   "execution_count": 6,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def sigmoid_prime(x,slope=1.0):\n",
    "    return slope*sigmoid(x,slope=slope)*(1.0-sigmoid(x,slope=slope))"
   ],
   "execution_count": 7,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "z = np.random.normal(size=5)\n",
    "gradient_checker(sigmoid, sigmoid_prime, z, eps=1e-4, rtol=1e-5)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed\n"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_digit(digit, size=8, caption=None):\n",
    "    digit = digit.reshape(size, size)\n",
    "    digit = (digit - np.min(digit))/(np.max(digit) - np.min(digit))\n",
    "    p = ggplot() + geom_image(image_data=digit) + labs(x='', y='') \\\n",
    "        + theme(axis_line='blank', axis_title='blank', axis_ticks='blank', axis_text='blank')\n",
    "    if caption:\n",
    "        p += ggtitle(caption)\n",
    "    return p;"
   ],
   "execution_count": 9,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def gg_confusion_matrix(y, y_hat):\n",
    "    conf_mat = confusion_matrix(y, y_hat)[::-1]\n",
    "    confusion_dat = pd.DataFrame(conf_mat)\n",
    "    observed = confusion_dat.columns.values\n",
    "    actual = confusion_dat.index.values\n",
    "    xx, yy = np.meshgrid(actual, observed)\n",
    "    xx = xx.reshape(-1)\n",
    "    yy = yy.reshape(-1)\n",
    "    zz = conf_mat.reshape(-1)\n",
    "    dat = {'predicted':xx, 'actual':yy[::-1], 'z':zz}\n",
    "    p = ggplot(dat, aes('predicted', 'actual', fill='z')) \\\n",
    "        + geom_raster() \\\n",
    "        + geom_text(aes(label='z'), color='white')\\\n",
    "        + theme(legend_position='none', axis_ticks='blank', axis_line='blank')\\\n",
    "        + ggsize(500, 500) + scale_x_discrete() + scale_y_discrete()\\\n",
    "        + ggtitle('Confusion matrix')\n",
    "    return p"
   ],
   "execution_count": 10,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def f1_score_micro(conf_matrix):\n",
    "    num_tags = conf_matrix.shape[0]\n",
    "    score = 0.\n",
    "    pr, p, r = 0., 0., 0.\n",
    "    for tag in range(num_tags):\n",
    "        pr += conf_matrix[tag, tag]\n",
    "        p += sum(conf_matrix[tag, :])\n",
    "        r += sum(conf_matrix[:, tag])\n",
    "    try:\n",
    "        score = 2 * pr / (p + r)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    return score"
   ],
   "execution_count": 11,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes"
   ],
   "execution_count": 12,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.ticker as ticker"
   ],
   "execution_count": 13,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import itertools"
   ],
   "execution_count": 14,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrix(conf_matrix, labels, title='Confusion matrix', cmap: str='Oranges'):\n",
    "    norm_cm = conf_matrix / conf_matrix.sum(axis=0)\n",
    "    norm_cm[norm_cm != norm_cm] = .0  # eliminate NaN\n",
    "    \n",
    "    fig: Figure = Figure(figsize=(7, 7))\n",
    "    ax: Axes = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_title(label=title)\n",
    "\n",
    "    ax.matshow(norm_cm, cmap=cmap)\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicted')\n",
    "\n",
    "    ax.set_xticklabels([''] + labels, rotation=90)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    ax.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "        ax.text(j, i, format(int(conf_matrix[i, j]), 'd') if conf_matrix[i, j] != 0 else '.',\n",
    "                horizontalalignment='center', verticalalignment='center', fontsize=6, color='black')\n",
    "    fig.set_tight_layout('true')\n",
    "    return fig"
   ],
   "execution_count": 15,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "execution_count": 15,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FFN"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "sheet_delimiter": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problems 1 and 2 starter code\n",
    "You can see below the starter code for the group of tasks related to forward networks."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from typing import List, Optional, Union\n",
    "import json\n",
    "import time"
   ],
   "execution_count": 16,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "digits_bunch = load_digits()\n",
    "digits_df = pd.DataFrame(digits_bunch.data)\n",
    "digits_df['target'] = pd.Series(pd.Categorical.from_codes(digits_bunch.target, categories=digits_bunch.target_names))"
   ],
   "execution_count": 17,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "type(digits_bunch)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "sklearn.utils.Bunch"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X, y = digits_df.drop('target', axis=1), digits_df['target']\n",
    "print('X shape: {}, y shape: {}'.format(X.shape, y.shape))"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1797, 64), y shape: (1797,)\n"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X, y = X.values, y.values\n",
    "y = y.astype(int)\n",
    "X = X / 16"
   ],
   "execution_count": 20,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, stratify=y_train_val, random_state=42)\n",
    "print('X_train shape: {}, X_val shape: {}, X_test shape: {}'.format(X_train.shape, X_val.shape, X_test.shape))"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1149, 64), X_val shape: (288, 64), X_test shape: (360, 64)\n"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "random_ind = np.random.randint(low=0, high=X.shape[0], size=100)\n",
    "digit_examples = X[random_ind]"
   ],
   "execution_count": 55,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bunch = GGBunch()\n",
    "x0, y0 = 0, 0\n",
    "row = 0\n",
    "col = 0\n",
    "width = 50\n",
    "height = width\n",
    "step = width + 0\n",
    "n_cols = 10\n",
    "for digit in digit_examples:\n",
    "    if col == n_cols:\n",
    "        col = 0\n",
    "        row += 1\n",
    "    plot = plot_digit(digit)\n",
    "    bunch.add_plot(plot, x0 + col*step, y0 + row*step, width, height)\n",
    "    col += 1\n",
    "bunch.show()"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GGBunch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [56]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m bunch \u001B[38;5;241m=\u001B[39m GGBunch()\n\u001B[1;32m      2\u001B[0m x0, y0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      3\u001B[0m row \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'GGBunch' is not defined"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Function:\n",
    "    def __call__(self) -> \"Tensor\":\n",
    "        pass\n",
    "    \n",
    "    def backward(self, *args, **kwargs):\n",
    "        pass"
   ],
   "execution_count": 22,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "    def __init__(self, data: np.ndarray, func: Optional[Function]=None, name: str=None):\n",
    "        self.data: np.ndarray = data\n",
    "        self.grad: np.ndarray = np.zeros(data.shape)\n",
    "        self.func = func\n",
    "        self.__name__ = name\n",
    "    \n",
    "    def backward(self, grad: Optional[np.ndarray] = None):\n",
    "        if grad is not None:\n",
    "            assert grad.shape == self.grad.shape\n",
    "            self.grad += grad\n",
    "            if self.func:\n",
    "                self.func.backward(grad)\n",
    "        else:\n",
    "            if self.func:\n",
    "                self.func.backward()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.grad[:] = .0\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.data.size\n",
    "    \n",
    "    def astype(self, dtype: Union[str, np.dtype]):\n",
    "        return self.data.astype(dtype)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return str(self.data)"
   ],
   "execution_count": 23,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.parameters: List[Tensor] = []\n",
    "        self.__name__ = self.__class__.__name__\n",
    "        self.state_dict = {}\n",
    "        self.training = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_module_state_dict(module: \"Module\"):\n",
    "        keys = [param.__name__ for param in module.__dict__['parameters']]\n",
    "        values = [param.data.tolist() for param in module.__dict__['parameters']]\n",
    "        return dict(zip(keys, values))\n",
    "     \n",
    "    def update_state_dict(self):\n",
    "        module_state_dicts = []\n",
    "        module_names = []\n",
    "        for key in self.__dict__:\n",
    "            value = self.__dict__[key]\n",
    "            base_class_name = value.__class__.__bases__[0].__name__\n",
    "            class_name = value.__class__.__name__\n",
    "            if base_class_name == 'Module':\n",
    "                class_has_parameters = hasattr(value, \"parameters\")\n",
    "                if class_has_parameters:\n",
    "                    parameters_not_empty = len(value.parameters) > 0\n",
    "                    if parameters_not_empty:\n",
    "                        module_names.append(key)\n",
    "                        module_state_dict = self.get_module_state_dict(value)\n",
    "                        module_state_dicts.append(module_state_dict)\n",
    "        self.state_dict = dict(zip(module_names, module_state_dicts))\n",
    "\n",
    "    def register_parameter(self, param: Tensor):\n",
    "        self.parameters.append(param)\n",
    "\n",
    "    def register_parameters(self, param_list_or_module: Union[List[Tensor], \"Module\", List[\"Module\"]]):\n",
    "        if isinstance(param_list_or_module, List):\n",
    "            for element in param_list_or_module:\n",
    "                if isinstance(element, Tensor):\n",
    "                    self.register_parameter(element)\n",
    "                elif isinstance(element, Module):\n",
    "                    for param in element.parameters:\n",
    "                        self.register_parameter(param)\n",
    "                else:\n",
    "                    raise TypeError(\"Parameter should be of type Tensor\")\n",
    "        elif isinstance(param_list_or_module, Module):\n",
    "            for param in param_list_or_module.parameters:\n",
    "                self.register_parameter(param)\n",
    "        self.update_state_dict()\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for param in self.parameters:\n",
    "            param.zero_grad()\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "    def size(self):\n",
    "        s = 0\n",
    "        for param in self.parameters:\n",
    "            s += param.data.size\n",
    "        return s\n",
    "    \n",
    "    def update_parameters_from_state_dict(self):\n",
    "        for key in self.__dict__:\n",
    "            if key in self.state_dict:\n",
    "                for param in self.__dict__[key].parameters:\n",
    "                    param.data = np.asarray(self.state_dict[key][param.__name__])\n",
    "\n",
    "    def save(self, filename: str = None):\n",
    "        if filename is None:\n",
    "            filename = time.strftime(\"%Y%m%d-%H%M%S\") + '.json'\n",
    "        self.update_state_dict()\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.state_dict, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    def load(self, filename: str):\n",
    "        with open(filename, 'r') as f:\n",
    "            json_str = f.read()\n",
    "            self.state_dict = json.loads(json_str)\n",
    "        self.update_parameters_from_state_dict()\n",
    "    \n",
    "    def train(self):\n",
    "        for key in self.__dict__:\n",
    "            module = self.__dict__[key]\n",
    "            base_class_name = module.__class__.__bases__[0].__name__\n",
    "            if base_class_name == 'Module':\n",
    "                module.training = True\n",
    "    \n",
    "    def eval(self):\n",
    "        for key in self.__dict__:\n",
    "            module = self.__dict__[key]\n",
    "            base_class_name = module.__class__.__bases__[0].__name__\n",
    "            if base_class_name == 'Module':\n",
    "                module.training = False"
   ],
   "execution_count": 24,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def Wandb(in_dim, out_dim):\n",
    "    W = np.random.normal(loc=0, scale=0.1, size=(in_dim, out_dim))\n",
    "    b = np.random.normal(loc=0, scale=0.1, size=(1, out_dim))\n",
    "    return Tensor(W, name='weights'), Tensor(b, name='bias')"
   ],
   "execution_count": 25,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Linear(Function):\n",
    "    def __init__(self, x: Tensor, W: Tensor, b: Tensor = None):\n",
    "        self.x = x\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self):\n",
    "        outputs = np.dot(self.x.data, self.W.data) + self.b.data\n",
    "        return Tensor(outputs, func=self)\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        dW = np.dot(self.x.data.T, grad)\n",
    "        db = grad.sum(axis=0)\n",
    "        grad = np.dot(grad, self.W.data.T)\n",
    "        self.W.backward(dW.reshape(self.W.shape))\n",
    "        self.b.backward(db.reshape(self.b.shape))\n",
    "        self.x.backward(grad.reshape(self.x.shape))"
   ],
   "execution_count": 26,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class LinearLayer(Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.W, self.b = Wandb(in_dim, out_dim)\n",
    "        self.register_parameters([self.W, self.b])\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return Linear(x, self.W, self.b)()"
   ],
   "execution_count": 27,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def sigmoid(x):\n",
    "    s = 1.0 / (1.0 + np.exp(-x))\n",
    "    return s"
   ],
   "execution_count": 28,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Sigmoid(Function):\n",
    "    def __init__(self, x: Tensor):\n",
    "        self.x = x\n",
    "\n",
    "    def __call__(self):\n",
    "        self.a = sigmoid(self.x.data)\n",
    "        return Tensor(self.a, self)\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        grad = self.a * (1. - self.a) * grad.reshape(self.a.shape)\n",
    "        self.x.backward(grad)"
   ],
   "execution_count": 29,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SigmoidFunction(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return Sigmoid(x)()"
   ],
   "execution_count": 30,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def softmax(x: Tensor):\n",
    "    a = np.amax(x.data, axis=1)[:, np.newaxis]\n",
    "    ex = np.exp(x.data - a)\n",
    "    ex_sum = np.sum(ex, axis=1)[:, np.newaxis]\n",
    "    out = ex / ex_sum\n",
    "    return Tensor(out, x.func)"
   ],
   "execution_count": 31,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def one_hot_encoder(labels: Tensor, n_classes=10):\n",
    "    encoded = np.zeros((labels.size, n_classes))\n",
    "    encoded[np.arange(labels.size), labels.astype(int)] = 1\n",
    "    return Tensor(encoded)"
   ],
   "execution_count": 32,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class NLL(Function):\n",
    "    def __init__(self, y_hat: Tensor, y: Tensor, eps: float = 1e-15):\n",
    "        self.y_hat = softmax(y_hat)\n",
    "        self.y = one_hot_encoder(y)\n",
    "        self.eps = eps\n",
    "\n",
    "    def __call__(self):\n",
    "        logs = np.log(self.y_hat.data + self.eps)\n",
    "        loss = np.multiply(-self.y.data, logs).sum(axis=1).sum()\n",
    "        return Tensor(loss, self)\n",
    "    \n",
    "    def backward(self):\n",
    "        grad = self.y_hat.data - self.y.data\n",
    "        self.y_hat.backward(grad)"
   ],
   "execution_count": 33,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CrossEntropyLoss(Module):\n",
    "    def __init__(self, eps=1e-15):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return NLL(output, target, self.eps)()"
   ],
   "execution_count": 34,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params: List[Tensor], lr: float = 0.001):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            param.zero_grad()"
   ],
   "execution_count": 35,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SGD(Optimizer):\n",
    "    def __init__(self, params: List[Tensor], lr: float = 0.001):\n",
    "        super().__init__(params, lr)\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param.data -= self.lr * param.grad"
   ],
   "execution_count": 36,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Scheduler:\n",
    "    def __init__(self, optimizer: Optimizer, last_epoch: int = -1):\n",
    "        self.optimizer = optimizer\n",
    "        self.base_lr = optimizer.lr\n",
    "        self.last_epoch = last_epoch\n",
    "    \n",
    "    def step(self):\n",
    "        raise NotImplementedError"
   ],
   "execution_count": 37,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ConstantLR(Scheduler):\n",
    "    def __init__(self, optimizer: Optimizer):\n",
    "        super().__init__(optimizer)\n",
    "        self.lr = optimizer.lr\n",
    "    \n",
    "    def step(self):\n",
    "        self.last_epoch += 1"
   ],
   "execution_count": 38,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CosineAnnealingLR(Scheduler):\n",
    "    def __init__(self, optimizer: Optimizer, T_max: int, eta_min: float = 0, anneal_epochs: int = None, last_epoch: int = -1):\n",
    "        super().__init__(optimizer)\n",
    "        self.T_max = T_max\n",
    "        self.eta_min = eta_min\n",
    "        self.lr = optimizer.lr\n",
    "        self.last_epoch = last_epoch\n",
    "        self.start_epoch = last_epoch\n",
    "        self.anneal_epochs = anneal_epochs\n",
    "    \n",
    "    @staticmethod\n",
    "    def _cosine_anneal(t):\n",
    "        return (1 + np.cos(np.pi * t)) / 2\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.anneal_epochs is not None:\n",
    "            passed_epochs = self.last_epoch - self.start_epoch\n",
    "            if passed_epochs > self.anneal_epochs:\n",
    "                return self.lr\n",
    "        t = self.last_epoch / self.T_max\n",
    "        return self.eta_min + (self.base_lr - self.eta_min) * self._cosine_anneal(t)\n",
    "    \n",
    "    def step(self):\n",
    "        self.lr = self.get_lr()\n",
    "        self.optimizer.lr = self.lr\n",
    "        self.last_epoch += 1"
   ],
   "execution_count": 39,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def xavier_(weights):\n",
    "    for weight in weights:\n",
    "        in_dim, out_dim = weight.shape[-2:]\n",
    "        np.copyto(dst=weight.data, src=np.random.randn(*weight.shape) * np.sqrt(2. / (in_dim + out_dim)))"
   ],
   "execution_count": 40,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Feedforward(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = LinearLayer(64, 32)\n",
    "        self.fc2 = LinearLayer(32, 10)\n",
    "        self.sigmoid = SigmoidFunction()\n",
    "\n",
    "        xavier_(self.fc1.parameters)\n",
    "        xavier_(self.fc2.parameters)\n",
    "        self.register_parameters([self.fc1, self.fc2])\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        z1 = self.fc1(x)\n",
    "        a1 = self.sigmoid(z1)\n",
    "        z2 = self.fc2(a1)\n",
    "        return z2"
   ],
   "execution_count": 41,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data, target, batch_size=20):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def next(self):\n",
    "        m, _ = self.data.shape\n",
    "        rand_index = np.random.choice(m, size=m, replace=False)\n",
    "        X, y = self.data[rand_index], self.target[rand_index]\n",
    "        pos = 0\n",
    "        while pos < m:\n",
    "            X_batch, y_batch = X[pos:pos+self.batch_size], y[pos:pos+self.batch_size]\n",
    "            yield Tensor(X_batch), Tensor(y_batch)\n",
    "            pos += self.batch_size\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.next()"
   ],
   "execution_count": 42,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def eval_accuracy(model, val, y_val):\n",
    "    output = model(Tensor(val))\n",
    "    y_hat = np.argmax(output.data, axis=1)\n",
    "    return accuracy_score(y_val, y_hat)"
   ],
   "execution_count": 43,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 50\n",
    "dataloader = DataLoader(X_train, y_train)\n",
    "model = Feedforward()\n",
    "loss_function = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters, lr=0.1)\n",
    "scheduler = ConstantLR(optimizer)"
   ],
   "execution_count": 44,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.size()"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "2410"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "lrs = []\n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "    for data in dataloader():\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.data\n",
    "    acc = eval_accuracy(model, X_val, y_val)\n",
    "    print(f'\\r epoch: [{epoch+1}/{num_epochs}], loss: {loss_sum}, acc: {acc}', end='')\n",
    "    losses.append(loss_sum)\n",
    "    accuracies.append(acc)\n",
    "    lrs.append(scheduler.lr)\n",
    "    scheduler.step()"
   ],
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: [50/50], loss: 5.427461441024057, acc: 0.98263888888888886"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = np.arange(num_epochs)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].plot(epochs, losses)\n",
    "ax[0].set_title('Losses')\n",
    "ax[1].plot(epochs, accuracies)\n",
    "ax[1].set_title('Accuracy');"
   ],
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x360 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train set confusion matrix"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "y_hat = model(Tensor(X_train))\n",
    "y_pred = np.argmax(y_hat.data, axis=1)"
   ],
   "execution_count": 48,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gg_confusion_matrix(y_train, y_pred) + ggsize(500, 500)"
   ],
   "execution_count": 49,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ggplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [49]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m gg_confusion_matrix(y_train, y_pred) \u001B[38;5;241m+\u001B[39m ggsize(\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m)\n",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36mgg_confusion_matrix\u001B[0;34m(y, y_hat)\u001B[0m\n\u001B[1;32m      9\u001B[0m zz \u001B[38;5;241m=\u001B[39m conf_mat\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     10\u001B[0m dat \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m:xx, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactual\u001B[39m\u001B[38;5;124m'\u001B[39m:yy[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m:zz}\n\u001B[0;32m---> 11\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43mggplot\u001B[49m(dat, aes(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactual\u001B[39m\u001B[38;5;124m'\u001B[39m, fill\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m)) \\\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;241m+\u001B[39m geom_raster() \\\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;241m+\u001B[39m geom_text(aes(label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m), color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwhite\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;241m+\u001B[39m theme(legend_position\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m, axis_ticks\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblank\u001B[39m\u001B[38;5;124m'\u001B[39m, axis_line\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblank\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;241m+\u001B[39m ggsize(\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m) \u001B[38;5;241m+\u001B[39m scale_x_discrete() \u001B[38;5;241m+\u001B[39m scale_y_discrete()\\\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;241m+\u001B[39m ggtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mConfusion matrix\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ggplot' is not defined"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_train, y_pred)\n",
    "score = f1_score_micro(cm)\n",
    "print(f'F1 score micro: {score}')"
   ],
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score micro: 1.0\n"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test set confusion matrix"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "y_hat = model(Tensor(X_test))\n",
    "y_pred = np.argmax(y_hat.data, axis=1)"
   ],
   "execution_count": 51,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gg_confusion_matrix(y_test, y_pred) + ggsize(500, 500)"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ggplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [52]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m gg_confusion_matrix(y_test, y_pred) \u001B[38;5;241m+\u001B[39m ggsize(\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m)\n",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36mgg_confusion_matrix\u001B[0;34m(y, y_hat)\u001B[0m\n\u001B[1;32m      9\u001B[0m zz \u001B[38;5;241m=\u001B[39m conf_mat\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     10\u001B[0m dat \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m:xx, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactual\u001B[39m\u001B[38;5;124m'\u001B[39m:yy[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m:zz}\n\u001B[0;32m---> 11\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43mggplot\u001B[49m(dat, aes(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactual\u001B[39m\u001B[38;5;124m'\u001B[39m, fill\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m)) \\\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;241m+\u001B[39m geom_raster() \\\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;241m+\u001B[39m geom_text(aes(label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m), color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwhite\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;241m+\u001B[39m theme(legend_position\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m, axis_ticks\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblank\u001B[39m\u001B[38;5;124m'\u001B[39m, axis_line\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblank\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;241m+\u001B[39m ggsize(\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m) \u001B[38;5;241m+\u001B[39m scale_x_discrete() \u001B[38;5;241m+\u001B[39m scale_y_discrete()\\\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;241m+\u001B[39m ggtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mConfusion matrix\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ggplot' is not defined"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = f1_score_micro(cm)\n",
    "print(f'F1 score micro: {score}')"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score micro: 0.975\n"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check gradients\n",
    "\n",
    "A very detailed list of tips and tricks for gradient checks and sanity checks can be found here: [http://cs231n.github.io/neural-networks-3/#ensemble](http://cs231n.github.io/neural-networks-3/#ensemble)"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def gradient_checker(J, grad_J, theta, eps=1e-5, rtol=1e-5):\n",
    "    \"\"\"Gradient checker for scalar and vector functions\n",
    "    Args:\n",
    "    J - function of theta\n",
    "    grad_J - gradient of function J\n",
    "    theta - the point for which to compute the numerical gradient\n",
    "    eps - step value in numerical gradient\n",
    "    rtol - relative tolerance threshold value\n",
    "    Returns:\n",
    "    error message if the relative tolerance is greater for some axis\n",
    "    or \"Gradient check passed\" else\n",
    "    \"\"\"\n",
    "    it = np.nditer(theta, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] += eps\n",
    "        J1 = J(theta_)\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] -= eps\n",
    "        J2 = J(theta_)\n",
    "\n",
    "        J1 = to_scalar(J1, ix)\n",
    "        J2 = to_scalar(J2, ix)\n",
    "\n",
    "        num_grad = (J1 - J2)/(2*eps)\n",
    "\n",
    "        rel_tol = np.abs(num_grad - grad_J)[ix]/(1. + np.minimum(np.abs(num_grad), np.abs(grad_J[ix])))\n",
    "\n",
    "        if rel_tol > rtol:\n",
    "            print(f'num_grad: {num_grad} grad: {grad_J[ix]} factor: {grad_J[ix] / num_grad}')\n",
    "            print(f'Incorrect gradient for the axis {str(ix)}')\n",
    "            return\n",
    "        it.iternext()\n",
    "    print(f'Gradient check passed')"
   ],
   "execution_count": 54,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def J_theta_global(model, loss_function, theta, idx, x, y):\n",
    "    original = model.parameters[idx].data.copy()\n",
    "    np.copyto(dst=model.parameters[idx].data, src=theta)\n",
    "    outputs = model(x)\n",
    "    loss_value = loss_function(outputs, y).data\n",
    "    np.copyto(dst=model.parameters[idx].data, src=original)\n",
    "    model.zero_grad()\n",
    "    return loss_value"
   ],
   "execution_count": 55,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def dJ_theta_global(model, loss_function, x, y):\n",
    "    outputs = model(x)\n",
    "    loss = loss_function(outputs, y)\n",
    "    loss.backward()\n",
    "    grads = []\n",
    "    for parameter in model.parameters:\n",
    "        grads.append(parameter.grad.copy())\n",
    "    model.zero_grad()\n",
    "    return grads"
   ],
   "execution_count": 56,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss_function = CrossEntropyLoss()\n",
    "model_ = Feedforward()\n",
    "dJ_theta_tensors = dJ_theta_global(model_, loss_function, Tensor(X_val), Tensor(y_val))\n",
    "global_start = time.time()\n",
    "for i, parameter in enumerate(model_.parameters):\n",
    "    start = time.time()\n",
    "    print(f'[{i}]: Start')\n",
    "    def J_theta(theta, idx=i, x=Tensor(X_val), y=Tensor(y_val)):\n",
    "        return J_theta_global(model_, loss_function, theta, idx, x, y)\n",
    "    gradient_checker(J_theta, dJ_theta_tensors[i], parameter.data)\n",
    "    print(f'[{i}]: Elapsed time: {time.time() - start:.1f}s')\n",
    "print(f'Total elapsed time: {time.time() - global_start:.1f}s')"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: Start\n",
      "Gradient check passed\n",
      "[0]: Elapsed time: 2.7s\n",
      "[1]: Start\n",
      "Gradient check passed\n",
      "[1]: Elapsed time: 0.0s\n",
      "[2]: Start\n",
      "Gradient check passed\n",
      "[2]: Elapsed time: 0.2s\n",
      "[3]: Start\n",
      "Gradient check passed\n",
      "[3]: Elapsed time: 0.0s\n",
      "Total elapsed time: 2.9s\n"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1: Dropout"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "sheet_delimiter": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 1: Dropout (2.0)\n",
    "Implement the dropout layer and check the resulting FFN model with ` gradient_check` (Note: you have to make corrections in gradient check in order to be able to check dropout with it. Why?). \n",
    "Take the description from the paper [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n",
    "\n",
    "Don't forget to scale the ouput inverse proportionally to the probability $p$ of keeping the forward signal.\n",
    "\n",
    "Add dropout layer to the model on Checks worksheet. Where would you insert it?"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DropoutFunction(Function):\n",
    "    def __init__(self, x, dropout_ratio, seed=None):\n",
    "        if not 0.0 <= dropout_ratio < 1.0:\n",
    "            raise ValueError('dropout_ratio must be in the range [0, 1)')\n",
    "\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.x = x\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def __call__(self):\n",
    "        self.mask = (np.random.rand(*self.x.shape) < self.dropout_ratio) / self.dropout_ratio\n",
    "        return Tensor(self.x.data * self.mask, func=self)\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        grad *= self.mask\n",
    "        self.x.backward(grad)"
   ],
   "execution_count": 58,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Dropout(Module):\n",
    "    def __init__(self, dropout_ratio=0.5, seed=26):\n",
    "        super().__init__()\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.seed = seed\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "\n",
    "        if self.training:\n",
    "            return DropoutFunction(x, self.dropout_ratio, self.seed)()\n",
    "\n",
    "        else:\n",
    "            return x"
   ],
   "execution_count": 65,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2: Adam"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "sheet_delimiter": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 2 (2.0)\n",
    "\n",
    "Implement Adam optimizer with weight decay (see the paper [Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101)) and check the implementation with the FFN model."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Adam(Optimizer):\n",
    "    def __init__(self, params: list[Tensor], lr: float = 0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, weight_decay=0.1,\n",
    "                 eta=1.0):\n",
    "        super().__init__(params, lr)\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.weight_decay = weight_decay\n",
    "        self.eta = eta\n",
    "        self.m = [np.zeros_like(param.data) for param in self.params]  #  \n",
    "        self.v = [np.zeros_like(param.data) for param in self.params]  #  \n",
    "        self.t = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.t = self.t + 1\n",
    "\n",
    "        for indeces, param in enumerate(self.params):\n",
    "            gradient = param.grad + (self.weight_decay * param.data)\n",
    "            self.m[indeces] = self.beta1 * self.m[indeces] + (1 - self.beta1) * gradient\n",
    "            self.v[indeces] = self.beta2 * self.v[indeces] + (1 - self.beta2) * (gradient ** 2)\n",
    "\n",
    "            m_hat = self.m[indeces] / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v[indeces] / (1 - self.beta2 ** self.t)\n",
    "\n",
    "            param.data -= self.eta * (\n",
    "                        self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon) + (self.weight_decay * param.data))"
   ],
   "execution_count": 66,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checks"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "sheet_delimiter": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add dropout layer to the model"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Feedforward(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = LinearLayer(64, 32)\n",
    "        self.fc2 = LinearLayer(32, 10)\n",
    "        self.sigmoid = SigmoidFunction()\n",
    "        self.dropout = Dropout(0.7, 26)\n",
    "\n",
    "        xavier_(self.fc1.parameters)\n",
    "        xavier_(self.fc2.parameters)\n",
    "        self.register_parameters([self.fc1, self.fc2])\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        z1 = self.fc1(x)\n",
    "        a1 = self.sigmoid(z1)\n",
    "        a1 = self.dropout(a1)\n",
    "        z2 = self.fc2(a1)\n",
    "        return z2"
   ],
   "execution_count": 67,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training: use Adam to train your model "
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 50\n",
    "swa_start = 5\n",
    "dataloader = DataLoader(X_train, y_train)\n",
    "model = Feedforward()\n",
    "loss_function = CrossEntropyLoss()\n",
    "# optimizer = SGD(model.parameters, lr=0.1)\n",
    "optimizer = Adam(model.parameters, lr=0.015, beta1=0.9, beta2=0.999, epsilon=1e-8)\n",
    "scheduler = ConstantLR(optimizer)"
   ],
   "execution_count": 68,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.size()"
   ],
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "2410"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "lrs = []\n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "    for data in dataloader():\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.data\n",
    "    acc = eval_accuracy(model, X_val, y_val)\n",
    "    print(f'\\r epoch: [{epoch + 1}/{num_epochs}], loss: {loss_sum}, acc: {acc} ', end='')\n",
    "    losses.append(loss_sum)\n",
    "    accuracies.append(acc)\n",
    "    lrs.append(scheduler.lr)\n",
    "    scheduler.step()"
   ],
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: [50/50], loss: 2619.9738154941715, acc: 0.14930555555555555 "
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = np.arange(num_epochs)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].plot(epochs, losses)\n",
    "ax[0].set_title('Losses')\n",
    "ax[1].plot(epochs, accuracies)\n",
    "ax[1].set_title('Accuracy');"
   ],
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x360 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train set confusion matrix"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "y_hat = model(Tensor(X_train))\n",
    "y_pred = np.argmax(y_hat.data, axis=1)"
   ],
   "execution_count": 72,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gg_confusion_matrix(y_train, y_pred) + ggsize(500, 500)"
   ],
   "execution_count": 73,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ggplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [73]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m gg_confusion_matrix(y_train, y_pred) \u001B[38;5;241m+\u001B[39m ggsize(\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m)\n",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36mgg_confusion_matrix\u001B[0;34m(y, y_hat)\u001B[0m\n\u001B[1;32m      9\u001B[0m zz \u001B[38;5;241m=\u001B[39m conf_mat\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     10\u001B[0m dat \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m:xx, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactual\u001B[39m\u001B[38;5;124m'\u001B[39m:yy[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m:zz}\n\u001B[0;32m---> 11\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43mggplot\u001B[49m(dat, aes(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactual\u001B[39m\u001B[38;5;124m'\u001B[39m, fill\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m)) \\\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;241m+\u001B[39m geom_raster() \\\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;241m+\u001B[39m geom_text(aes(label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m), color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwhite\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;241m+\u001B[39m theme(legend_position\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m, axis_ticks\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblank\u001B[39m\u001B[38;5;124m'\u001B[39m, axis_line\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblank\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;241m+\u001B[39m ggsize(\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m) \u001B[38;5;241m+\u001B[39m scale_x_discrete() \u001B[38;5;241m+\u001B[39m scale_y_discrete()\\\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;241m+\u001B[39m ggtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mConfusion matrix\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ggplot' is not defined"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_train, y_pred)\n",
    "score = f1_score_micro(cm)\n",
    "print(f'F1 score micro: {score}')"
   ],
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score micro: 0.17493472584856398\n"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test set confusion matrix"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "y_hat = model(Tensor(X_test))\n",
    "y_pred = np.argmax(y_hat.data, axis=1)"
   ],
   "execution_count": 75,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gg_confusion_matrix(y_test, y_pred) + ggsize(500, 500)"
   ],
   "execution_count": 76,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ggplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [76]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m gg_confusion_matrix(y_test, y_pred) \u001B[38;5;241m+\u001B[39m ggsize(\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m)\n",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36mgg_confusion_matrix\u001B[0;34m(y, y_hat)\u001B[0m\n\u001B[1;32m      9\u001B[0m zz \u001B[38;5;241m=\u001B[39m conf_mat\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     10\u001B[0m dat \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m:xx, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactual\u001B[39m\u001B[38;5;124m'\u001B[39m:yy[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m:zz}\n\u001B[0;32m---> 11\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43mggplot\u001B[49m(dat, aes(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactual\u001B[39m\u001B[38;5;124m'\u001B[39m, fill\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m)) \\\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;241m+\u001B[39m geom_raster() \\\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;241m+\u001B[39m geom_text(aes(label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m'\u001B[39m), color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwhite\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;241m+\u001B[39m theme(legend_position\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m, axis_ticks\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblank\u001B[39m\u001B[38;5;124m'\u001B[39m, axis_line\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblank\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;241m+\u001B[39m ggsize(\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m) \u001B[38;5;241m+\u001B[39m scale_x_discrete() \u001B[38;5;241m+\u001B[39m scale_y_discrete()\\\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;241m+\u001B[39m ggtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mConfusion matrix\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ggplot' is not defined"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "score = f1_score_micro(cm)\n",
    "print(f'F1 score micro: {score}')"
   ],
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score micro: 0.175\n"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check gradients: introduce corrections, which will allow you to check dropout (hint: in three blocks below)"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def gradient_checker(J, grad_J, theta, eps=1e-5, rtol=1e-5):\n",
    "    \"\"\"Gradient checker for scalar and vector functions\n",
    "Args:\n",
    "    J - function of theta\n",
    "    grad_J - gradient of function J\n",
    "    theta - the point for which to compute the numerical gradient\n",
    "    eps - step value in numerical gradient\n",
    "    rtol - relative tolerance threshold value\n",
    "\n",
    "Returns:\n",
    "    error message if the relative tolerance is greater for some axis\n",
    "    or \"Gradient check passed\" else\n",
    "\"\"\"\n",
    "    it = np.nditer(theta, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] += eps\n",
    "        J1 = J(theta_)\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] -= eps\n",
    "        J2 = J(theta_)\n",
    "\n",
    "        J1 = to_scalar(J1, ix)\n",
    "        J2 = to_scalar(J2, ix)\n",
    "\n",
    "        num_grad = (J1 - J2) / (2 * eps)\n",
    "\n",
    "        rel_tol = np.abs(num_grad - grad_J)[ix] / (1. + np.minimum(np.abs(num_grad), np.abs(grad_J[ix])))\n",
    "\n",
    "        if rel_tol > rtol:\n",
    "            print(f'num_grad: {num_grad} grad: {grad_J[ix]} factor: {grad_J[ix] / num_grad}')\n",
    "            print(f'Incorrect gradient for the axis {str(ix)}')\n",
    "            return\n",
    "        it.iternext()\n",
    "    print(f'Gradient check passed')\n"
   ],
   "execution_count": 78,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def J_theta_global(model, loss_function, theta, idx, x, y):\n",
    "    original = model.parameters[idx].data.copy()\n",
    "    np.copyto(dst=model.parameters[idx].data, src=theta)\n",
    "    outputs = model(x)\n",
    "    loss_value = loss_function(outputs, y).data\n",
    "    np.copyto(dst=model.parameters[idx].data, src=original)\n",
    "    model.zero_grad()\n",
    "    return loss_value"
   ],
   "execution_count": 79,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def dJ_theta_global(model, loss_function, x, y):\n",
    "    outputs = model(x)\n",
    "    loss = loss_function(outputs, y)\n",
    "    loss.backward()\n",
    "    grads = []\n",
    "    for parameter in model.parameters:\n",
    "        grads.append(parameter.grad.copy())\n",
    "    model.zero_grad()\n",
    "    return grads"
   ],
   "execution_count": 80,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss_function = CrossEntropyLoss()\n",
    "model_ = Feedforward()\n",
    "dJ_theta_tensors = dJ_theta_global(model_, loss_function, Tensor(X_val), Tensor(y_val))\n",
    "global_start = time.time()\n",
    "for i, parameter in enumerate(model_.parameters):\n",
    "    start = time.time()\n",
    "    print(f'[{i}]: Start')\n",
    "    def J_theta(theta, idx=i, x=Tensor(X_val), y=Tensor(y_val)):\n",
    "        return J_theta_global(model_, loss_function, theta, idx, x, y)\n",
    "    gradient_checker(J_theta, dJ_theta_tensors[i], parameter.data)\n",
    "    print(f'[{i}]: Elapsed time: {time.time() - start:.1f}s')\n",
    "print(f'Total elapsed time: {time.time() - global_start:.1f}s')"
   ],
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: Start\n",
      "Gradient check passed\n",
      "[0]: Elapsed time: 2.9s\n",
      "[1]: Start\n",
      "Gradient check passed\n",
      "[1]: Elapsed time: 0.0s\n",
      "[2]: Start\n",
      "Gradient check passed\n",
      "[2]: Elapsed time: 0.3s\n",
      "[3]: Start\n",
      "Gradient check passed\n",
      "[3]: Elapsed time: 0.0s\n",
      "Total elapsed time: 3.2s\n"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3: Adversarial Attack"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "sheet_delimiter": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 3 (4.0)\n",
    "\n",
    "Using `PyTorch` write an implementation of the adversarial attack (any kind you like) for a classifier on MNIST digits.\n",
    "\n",
    "You can provide a link to your repository if you like, or just write or copy code here."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import itertools\n",
    "from copy import copy\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.stats import norm, uniform\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve\n",
    "\n",
    "data = pd.read_csv(\"mnist_train.csv\")\n",
    "\n",
    "X_train, y_train = data.values[:, 1:] / 255, data.values[:, 0]\n",
    "\n",
    "data = pd.read_csv(\"mnist_test.csv\")\n",
    "\n",
    "X_test, y_test = data.values[:, 1:] / 255, data.values[:, 0]\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.Tensor(X).float()\n",
    "        self.y = torch.Tensor(y).long()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "\n",
    "dataset = Data(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net(X_train.shape[1])\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "losses = []\n",
    "epoch = 30\n",
    "\n",
    "for i in range(epoch):\n",
    "    sum_loss = 0\n",
    "\n",
    "    for batch in iter(dataloader):\n",
    "        X_, y_ = batch\n",
    "        y_hat = model(X_)\n",
    "        loss = loss_function(y_hat, y_.long())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        sum_loss += loss.item()\n",
    "    losses.append(sum_loss)\n",
    "\n",
    "    if (i + 1) % 5 == 0 or i == 0:\n",
    "        print(\"Episode:\", i + 1, \"Loss:\", sum_loss)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(list(range(epoch)), losses)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def predict(X):\n",
    "    X = torch.Tensor(X).float()\n",
    "    y_hat = F.softmax(model(X), 1).detach().numpy()\n",
    "    return np.argmax(y_hat, axis=1), y_hat\n",
    "\n",
    "\n",
    "y_pred, _ = predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, range(10), range(10))\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "sn.set(font_scale=1)  # for label size\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"   =\", np.sum(predict(X_test)[0] == y_test) / len(y_test))\n",
    "\n",
    "\n",
    "def fast_adversarial_example(dig, n=784, n_classes=10, eta=0.01, iters=10):\n",
    "    y = torch.tensor([dig]).long()\n",
    "    x = torch.tensor(np.random.normal(loc=0, scale=0.01, size=n)).float()\n",
    "    for _ in range(iters):\n",
    "        x = Variable(x.data.clone(), requires_grad=True)\n",
    "        y_hat = model(x).unsqueeze(0)\n",
    "        loss = loss_function(y_hat, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = x.grad.data\n",
    "        x = torch.clamp(x - eta * grad.sign(), 0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "example = fast_adversarial_example(8, eta=0.1, iters=5)\n",
    "\n",
    "alpha = 0.5\n",
    "X_spoiled = np.maximum(X_test * (1 - alpha), alpha * example.detach().numpy())\n",
    "y_test_model, _ = predict(X_spoiled)\n",
    "\n",
    "print(\"   =\", np.sum(predict(X_spoiled)[0] == y_test) / len(y_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_model)\n",
    "df_cm = pd.DataFrame(cm, range(10), range(10))\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "sn.set(font_scale=1)  # for label size\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x_target = np.array([X_spoiled[0]])\n",
    "y_pred, score = predict(x_target)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "pixels = x_target.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.title(f'Predicted digit: {y_pred}, Actual digit: {y_test[0]}')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.bar(range(10), score[0])\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('labels')\n",
    "\n",
    "plt.show()\n"
   ],
   "execution_count": 82,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [82]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msn\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcopy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m copy\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'seaborn'"
     ]
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DUE DATE"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "sheet_delimiter": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The due date is 13 of April 2022 23:59:59\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* To submit the assignment, share your workbook with me (with **Can edit** access rights).\n",
    "\n",
    "* Check, that you found all the tasks in the workbook.  "
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    }
   }
  }
 ],
 "metadata": {
  "datalore": {
   "version": 1,
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "base_environment": "default",
   "packages": [
    {
     "name": "datalore",
     "version": "0.1.0",
     "source": "PIP"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}